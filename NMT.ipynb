{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "DlHS4FmMBpv2",
    "outputId": "37efd8f7-5f29-4755-e94f-dabaf8bc44c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
      "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (592.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 592.3MB 47.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.14.6)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-0.3.0.post4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "M0F2kKfGBt0L",
    "outputId": "5e65fd03-29d8-4b4d-9231-07d93c859859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
      "\r",
      "\u001b[K    18% |██████                          | 10kB 21.8MB/s eta 0:00:01\r",
      "\u001b[K    37% |████████████                    | 20kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K    56% |██████████████████              | 30kB 7.1MB/s eta 0:00:01\r",
      "\u001b[K    75% |████████████████████████        | 40kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K    93% |██████████████████████████████  | 51kB 5.6MB/s eta 0:00:01\r",
      "\u001b[K    100% |████████████████████████████████| 61kB 5.9MB/s \n",
      "\u001b[?25hCollecting pillow>=4.1.1 (from torchvision)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 11.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.3.0.post4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision) (3.13)\n",
      "Installing collected packages: pillow, torchvision\n",
      "  Found existing installation: Pillow 4.0.0\n",
      "    Uninstalling Pillow-4.0.0:\n",
      "      Successfully uninstalled Pillow-4.0.0\n",
      "Successfully installed pillow-5.4.1 torchvision-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCISE2GiBvhR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "import nltk\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "from torch.nn.utils.rnn import PackedSequence,pack_padded_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "random.seed(1024)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1PcKWWiNOtlg"
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "gpus = [0]\n",
    "torch.cuda.set_device(gpus[0])\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Gp2rZYe92ZJ"
   },
   "outputs": [],
   "source": [
    "def getBatch(batch_size, train_data):\n",
    "    random.shuffle(train_data)\n",
    "    sindex=0\n",
    "    eindex=batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex: eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "    \n",
    "    if eindex >= len(train_data):\n",
    "        batch = train_data[sindex:]\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGbH7qeHHI7-"
   },
   "outputs": [],
   "source": [
    "def pad_to_batch(batch, x_to_ix, y_to_ix):\n",
    "    \n",
    "    sorted_batch =  sorted(batch, key=lambda b:b[0].size(1), reverse=True) # sort by len\n",
    "    x,y = list(zip(*sorted_batch))\n",
    "    max_x = max([s.size(1) for s in x])\n",
    "    max_y = max([s.size(1) for s in y])\n",
    "    x_p, y_p = [], []\n",
    "    for i in range(len(batch)):\n",
    "        if x[i].size(1) < max_x:\n",
    "            x_p.append(torch.cat([x[i], Variable(LongTensor([x_to_ix['<PAD>']] * (max_x - x[i].size(1)))).view(1, -1)], 1))\n",
    "        else:\n",
    "            x_p.append(x[i])\n",
    "        if y[i].size(1) < max_y:\n",
    "            y_p.append(torch.cat([y[i], Variable(LongTensor([y_to_ix['<PAD>']] * (max_y - y[i].size(1)))).view(1, -1)], 1))\n",
    "        else:\n",
    "            y_p.append(y[i])\n",
    "        \n",
    "    input_var = torch.cat(x_p)\n",
    "    target_var = torch.cat(y_p)\n",
    "    input_len = [list(map(lambda s: s ==0, t.data)).count(False) for t in input_var]\n",
    "    target_len = [list(map(lambda s: s ==0, t.data)).count(False) for t in target_var]\n",
    "    \n",
    "    return input_var, target_var, input_len, target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AwcN7_8sx8I1"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([,.!?])\", r\" \\1 \", s)\n",
    "    s = re.sub(r\"[^a-zA-Z,.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LVoPaKt2CrbJ"
   },
   "outputs": [],
   "source": [
    "corpus = open('fra.txt', 'r', encoding='utf-8').readlines()\n",
    "corpus = corpus[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GN98CR18DP3U"
   },
   "outputs": [],
   "source": [
    "MIN_LENGTH = 3\n",
    "MAX_LENGTH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "AGb52VtkQ3sX",
    "outputId": "09a81be1-f8f4-496d-dc95-6b11b3bd42a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29807 29807\n",
      "['i', 'see', '.'] ['je', 'comprends', '.']\n"
     ]
    }
   ],
   "source": [
    "X_r, y_r = [], [] # raw\n",
    "\n",
    "for parallel in corpus:\n",
    "    so,ta = parallel[:-1].split('\\t')\n",
    "    if so.strip() == \"\" or ta.strip() == \"\": \n",
    "        continue\n",
    "    \n",
    "    normalized_so = normalize_string(so).split()\n",
    "    normalized_ta = normalize_string(ta).split()\n",
    "    \n",
    "    if len(normalized_so) >= MIN_LENGTH and len(normalized_so) <= MAX_LENGTH \\\n",
    "    and len(normalized_ta) >= MIN_LENGTH and len(normalized_ta) <= MAX_LENGTH:\n",
    "        X_r.append(normalized_so)\n",
    "        y_r.append(normalized_ta)\n",
    "    \n",
    "\n",
    "print(len(X_r), len(y_r))\n",
    "print(X_r[0], y_r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TaadjJgPANRb",
    "outputId": "230a4d76-1ac3-4059-f68b-79c4679a4cd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'try', '.'] ['j', 'essaye', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_r[1], y_r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ru3yx98C1i-a",
    "outputId": "ec2350c6-eb63-418f-e1bc-8be88663f7dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4443\n",
      "7664\n"
     ]
    }
   ],
   "source": [
    "#Building vocabulary\n",
    "source_vocab = list(set(flatten(X_r)))\n",
    "target_vocab = list(set(flatten(y_r)))\n",
    "print(len(source_vocab))\n",
    "print(len(target_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I9jTZVmw1pcs"
   },
   "outputs": [],
   "source": [
    "source_to_index = {\"<PAD>\":0, \"<UNK>\":1, \"<s>\":2, \"</s>\":3}\n",
    "for word in source_vocab:\n",
    "    if(word not in source_to_index):\n",
    "        source_to_index[word]=len(source_to_index)\n",
    "index_to_source = {v:k for k, v in source_to_index.items()}\n",
    "\n",
    "target_to_index = {\"<PAD>\":0, \"<UNK>\":1, \"<s>\":2, \"</s>\":3}\n",
    "for word in target_vocab:\n",
    "    if(word not in target_to_index):\n",
    "        target_to_index[word]=len(target_to_index)\n",
    "index_to_target = {v:k for k, v in target_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z7-fZ_C66yki"
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_index):\n",
    "    idxs = list(map(lambda w: to_index[w] if to_index.get(w) is not None else to_index[\"<UNK>\"], seq))\n",
    "    return Variable(LongTensor(idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wtr_gsAC60k5"
   },
   "outputs": [],
   "source": [
    "X_p, y_p = [], []\n",
    "\n",
    "for so, ta in zip(X_r, y_r):\n",
    "    X_p.append(prepare_sequence(so + ['</s>'], source_to_index).view(1, -1))\n",
    "    y_p.append(prepare_sequence(ta + ['</s>'], target_to_index).view(1, -1))\n",
    "    \n",
    "train_data = list(zip(X_p, y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "A24naEAFBala",
    "outputId": "dc94d1ad-c082-46ab-da1c-970789141ffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2948  4301  2660  2620  3972     3\n",
      "[torch.cuda.LongTensor of size 1x6 (GPU 0)]\n",
      " Variable containing:\n",
      "  992  2207   565  5234   642   897  6095  3670     3\n",
      "[torch.cuda.LongTensor of size 1x9 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X_p[10000],y_p[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L_MT_S_k8zmI"
   },
   "outputs": [],
   "source": [
    "#Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1, bidirec=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_size=input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        \n",
    "        if (bidirec == False):\n",
    "            self.n_direction=1\n",
    "            self.gru=nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True)\n",
    "        else:\n",
    "            self.n_direction=2\n",
    "            self.gru=nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True, bidirectional=True)\n",
    "    \n",
    "    def init_hidden(self, inputs):\n",
    "        hidden = Variable(torch.zeros(self.n_layers*self.n_direction, inputs.size(0), self.hidden_size))\n",
    "        return hidden.cuda() if USE_CUDA else hidden\n",
    "    \n",
    "    def init_weight(self):\n",
    "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
    "        self.gru.weight_hh_l0 = nn.init.xavier_uniform(self.gru.weight_hh_l0)\n",
    "        self.gru.weight_ih_l0 = nn.init.xavier_uniform(self.gru.weight_ih_l0)\n",
    "        \n",
    "    def forward(self, inputs, input_length):\n",
    "        hidden = self.init_hidden(inputs)\n",
    "        embedded = self.embedding(inputs)\n",
    "        packed = pack_padded_sequence(embedded, input_length, batch_first=True)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "        \n",
    "        if self.n_layers>.1:\n",
    "            if self.n_direction == 2:\n",
    "                hidden = hidden[-2:]\n",
    "            else:\n",
    "                hidden=hidden[-1]\n",
    "        return outputs, torch.cat([h for h in hidden], 1).unsqueeze(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXoEbbFwwvz0"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1, dropout_p=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size=hidden_size\n",
    "        self.n_layers=n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(embedding_size + hidden_size, hidden_size, n_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(2*hidden_size + embedding_size, input_size) #changed\n",
    "        self.attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "    \n",
    "    def init_hidden(self, inputs):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, inputs.size(0), self.hidden_size))\n",
    "        return hidden.cuda() if USE_CUDA else hidden\n",
    "    \n",
    "    def init_weight(self):\n",
    "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
    "        self.gru.weight_hh_l0 = nn.init.xavier_uniform(self.gru.weight_hh_l0)\n",
    "        self.gru.weight_ih_l0 = nn.init.xavier_uniform(self.gru.weight_ih_l0)\n",
    "        self.linear.weight = nn.init.xavier_uniform(self.linear.weight)\n",
    "        self.attn.weight = nn.init.xavier_uniform(self.attn.weight)\n",
    "    \n",
    "    def Attention(self, hidden, encoder_outputs, encoder_masking):\n",
    "        hidden=hidden[0].unsqueeze(2)\n",
    "        \n",
    "        batch_size = encoder_outputs.size(0) \n",
    "        max_len = encoder_outputs.size(1)\n",
    "        energies = self.attn(encoder_outputs.contiguous().view(batch_size * max_len, -1)) \n",
    "        energies = energies.view(batch_size,max_len, -1) \n",
    "        attn_energies = energies.bmm(hidden).squeeze(2) \n",
    "        \n",
    "     \n",
    "        alpha = F.softmax(attn_energies,1) \n",
    "        alpha = alpha.unsqueeze(1) \n",
    "        context = alpha.bmm(encoder_outputs) \n",
    "        \n",
    "        return context, alpha\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs, context, max_length, encoder_outputs, encoder_masking=None, is_training=False):\n",
    "        hidden = self.init_hidden(inputs)\n",
    "        embedded = self.embedding(inputs)\n",
    "        if is_training:\n",
    "            embedded = self.dropout(embedded)\n",
    "        decode =[]\n",
    "        \n",
    "        for i in range(0, max_length):\n",
    "            _, hidden = self.gru(torch.cat((embedded, context), 2), hidden)\n",
    "            score = self.linear(torch.cat((hidden, context.transpose(0,1), embedded.transpose(0,1)),2).squeeze(0)) #changed\n",
    "            softmaxed = F.log_softmax(score,1)\n",
    "            decode.append(softmaxed)\n",
    "            decoded = softmaxed.max(1)[1]\n",
    "            embedded = self.embedding(decoded).unsqueeze(1) # y_{t-1}\n",
    "            if is_training:\n",
    "                embedded = self.dropout(embedded)\n",
    "            context, alpha = self.Attention(hidden, encoder_outputs, encoder_masking)\n",
    "        scores = torch.cat(decode, 1)\n",
    "        return scores.view(inputs.size(0) * max_length, -1)\n",
    "    \n",
    "    def decode(self, context, encoder_outputs):\n",
    "        start_decode = Variable(LongTensor([[target_to_index['<s>']] * 1])).transpose(0, 1)\n",
    "        embedded = self.embedding(start_decode)\n",
    "        hidden = self.init_hidden(start_decode)\n",
    "        \n",
    "        decodes = []\n",
    "        attentions = []\n",
    "        decoded = embedded\n",
    "        while decoded.data.tolist()[0] != target_to_index['</s>']: # until </s>\n",
    "            _, hidden = self.gru(torch.cat((embedded, context), 2), hidden) # h_t = f(h_{t-1},y_{t-1},c)\n",
    "            concated = torch.cat((hidden, context.transpose(0, 1), embedded.transpose(0,1)), 2) # y_t = g(h_t,y_{t-1},c)  changed\n",
    "            score = self.linear(concated.squeeze(0))\n",
    "            softmaxed = F.log_softmax(score,1)\n",
    "            decodes.append(softmaxed)\n",
    "            decoded = softmaxed.max(1)[1]\n",
    "            embedded = self.embedding(decoded).unsqueeze(1) # y_{t-1}\n",
    "            context, alpha = self.Attention(hidden, encoder_outputs,None)\n",
    "            attentions.append(alpha.squeeze(1))\n",
    "        \n",
    "        return torch.cat(decodes).max(1)[1], torch.cat(attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqgO2EQnNz6x"
   },
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "\n",
    "EPOCH = 50\n",
    "BATCH_SIZE = 64\n",
    "EMBEDDING_SIZE = 300\n",
    "HIDDEN_SIZE = 512\n",
    "LR = 0.001\n",
    "DECODER_LEARNING_RATIO = 5.0\n",
    "RESCHEDULED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3B3IlW7EN55T"
   },
   "outputs": [],
   "source": [
    "encoder=Encoder(len(source_to_index), EMBEDDING_SIZE, HIDDEN_SIZE, 3, True)\n",
    "decoder = Decoder(len(target_to_index), EMBEDDING_SIZE, HIDDEN_SIZE * 2)\n",
    "encoder.init_weight()\n",
    "decoder.init_weight()\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "    \n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "enc_optimizer = optim.Adam(encoder.parameters(), lr=LR)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(), lr=LR * DECODER_LEARNING_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2567
    },
    "colab_type": "code",
    "id": "jIlzPmoJ_v5Z",
    "outputId": "2796bfcd-f206-4154-f5c9-eddef570df07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00/50] [000/465] mean_loss : 8.95\n",
      "[00/50] [200/465] mean_loss : 4.25\n",
      "[00/50] [400/465] mean_loss : 3.28\n",
      "[01/50] [000/465] mean_loss : 2.69\n",
      "[01/50] [200/465] mean_loss : 2.50\n",
      "[01/50] [400/465] mean_loss : 2.39\n",
      "[02/50] [000/465] mean_loss : 1.91\n",
      "[02/50] [200/465] mean_loss : 1.92\n",
      "[02/50] [400/465] mean_loss : 1.92\n",
      "[03/50] [000/465] mean_loss : 1.38\n",
      "[03/50] [200/465] mean_loss : 1.76\n",
      "[03/50] [400/465] mean_loss : 1.70\n",
      "[04/50] [000/465] mean_loss : 1.56\n",
      "[04/50] [200/465] mean_loss : 1.40\n",
      "[04/50] [400/465] mean_loss : 1.45\n",
      "[05/50] [000/465] mean_loss : 1.53\n",
      "[05/50] [200/465] mean_loss : 1.27\n",
      "[05/50] [400/465] mean_loss : 1.34\n",
      "[06/50] [000/465] mean_loss : 1.13\n",
      "[06/50] [200/465] mean_loss : 1.18\n",
      "[06/50] [400/465] mean_loss : 1.25\n",
      "[07/50] [000/465] mean_loss : 0.89\n",
      "[07/50] [200/465] mean_loss : 1.09\n",
      "[07/50] [400/465] mean_loss : 1.20\n",
      "[08/50] [000/465] mean_loss : 1.14\n",
      "[08/50] [200/465] mean_loss : 1.04\n",
      "[08/50] [400/465] mean_loss : 1.14\n",
      "[09/50] [000/465] mean_loss : 1.08\n",
      "[09/50] [200/465] mean_loss : 0.99\n",
      "[09/50] [400/465] mean_loss : 1.10\n",
      "[10/50] [000/465] mean_loss : 0.92\n",
      "[10/50] [200/465] mean_loss : 0.97\n",
      "[10/50] [400/465] mean_loss : 1.07\n",
      "[11/50] [000/465] mean_loss : 0.83\n",
      "[11/50] [200/465] mean_loss : 0.92\n",
      "[11/50] [400/465] mean_loss : 1.01\n",
      "[12/50] [000/465] mean_loss : 0.90\n",
      "[12/50] [200/465] mean_loss : 0.87\n",
      "[12/50] [400/465] mean_loss : 0.99\n",
      "[13/50] [000/465] mean_loss : 0.81\n",
      "[13/50] [200/465] mean_loss : 0.87\n",
      "[13/50] [400/465] mean_loss : 0.99\n",
      "[14/50] [000/465] mean_loss : 0.92\n",
      "[14/50] [200/465] mean_loss : 0.85\n",
      "[14/50] [400/465] mean_loss : 0.93\n",
      "[15/50] [000/465] mean_loss : 0.77\n",
      "[15/50] [200/465] mean_loss : 0.86\n",
      "[15/50] [400/465] mean_loss : 0.92\n",
      "[16/50] [000/465] mean_loss : 0.90\n",
      "[16/50] [200/465] mean_loss : 0.83\n",
      "[16/50] [400/465] mean_loss : 0.90\n",
      "[17/50] [000/465] mean_loss : 0.67\n",
      "[17/50] [200/465] mean_loss : 0.78\n",
      "[17/50] [400/465] mean_loss : 0.86\n",
      "[18/50] [000/465] mean_loss : 0.88\n",
      "[18/50] [200/465] mean_loss : 0.75\n",
      "[18/50] [400/465] mean_loss : 0.84\n",
      "[19/50] [000/465] mean_loss : 0.68\n",
      "[19/50] [200/465] mean_loss : 0.73\n",
      "[19/50] [400/465] mean_loss : 0.85\n",
      "[20/50] [000/465] mean_loss : 0.56\n",
      "[20/50] [200/465] mean_loss : 0.72\n",
      "[20/50] [400/465] mean_loss : 0.82\n",
      "[21/50] [000/465] mean_loss : 0.69\n",
      "[21/50] [200/465] mean_loss : 0.71\n",
      "[21/50] [400/465] mean_loss : 0.82\n",
      "[22/50] [000/465] mean_loss : 0.62\n",
      "[22/50] [200/465] mean_loss : 0.70\n",
      "[22/50] [400/465] mean_loss : 0.79\n",
      "[23/50] [000/465] mean_loss : 0.78\n",
      "[23/50] [200/465] mean_loss : 0.70\n",
      "[23/50] [400/465] mean_loss : 0.82\n",
      "[24/50] [000/465] mean_loss : 0.67\n",
      "[24/50] [200/465] mean_loss : 0.71\n",
      "[24/50] [400/465] mean_loss : 0.84\n",
      "[25/50] [000/465] mean_loss : 0.69\n",
      "[25/50] [200/465] mean_loss : 0.64\n",
      "[25/50] [400/465] mean_loss : 0.63\n",
      "[26/50] [000/465] mean_loss : 0.74\n",
      "[26/50] [200/465] mean_loss : 0.59\n",
      "[26/50] [400/465] mean_loss : 0.58\n",
      "[27/50] [000/465] mean_loss : 0.53\n",
      "[27/50] [200/465] mean_loss : 0.56\n",
      "[27/50] [400/465] mean_loss : 0.54\n",
      "[28/50] [000/465] mean_loss : 0.46\n",
      "[28/50] [200/465] mean_loss : 0.53\n",
      "[28/50] [400/465] mean_loss : 0.52\n",
      "[29/50] [000/465] mean_loss : 0.35\n",
      "[29/50] [200/465] mean_loss : 0.51\n",
      "[29/50] [400/465] mean_loss : 0.51\n",
      "[30/50] [000/465] mean_loss : 0.66\n",
      "[30/50] [200/465] mean_loss : 0.50\n",
      "[30/50] [400/465] mean_loss : 0.49\n",
      "[31/50] [000/465] mean_loss : 0.36\n",
      "[31/50] [200/465] mean_loss : 0.47\n",
      "[31/50] [400/465] mean_loss : 0.47\n",
      "[32/50] [000/465] mean_loss : 0.43\n",
      "[32/50] [200/465] mean_loss : 0.46\n",
      "[32/50] [400/465] mean_loss : 0.46\n",
      "[33/50] [000/465] mean_loss : 0.53\n",
      "[33/50] [200/465] mean_loss : 0.44\n",
      "[33/50] [400/465] mean_loss : 0.44\n",
      "[34/50] [000/465] mean_loss : 0.43\n",
      "[34/50] [200/465] mean_loss : 0.44\n",
      "[34/50] [400/465] mean_loss : 0.43\n",
      "[35/50] [000/465] mean_loss : 0.44\n",
      "[35/50] [200/465] mean_loss : 0.42\n",
      "[35/50] [400/465] mean_loss : 0.43\n",
      "[36/50] [000/465] mean_loss : 0.58\n",
      "[36/50] [200/465] mean_loss : 0.42\n",
      "[36/50] [400/465] mean_loss : 0.41\n",
      "[37/50] [000/465] mean_loss : 0.42\n",
      "[37/50] [200/465] mean_loss : 0.40\n",
      "[37/50] [400/465] mean_loss : 0.40\n",
      "[38/50] [000/465] mean_loss : 0.47\n",
      "[38/50] [200/465] mean_loss : 0.40\n",
      "[38/50] [400/465] mean_loss : 0.40\n",
      "[39/50] [000/465] mean_loss : 0.36\n",
      "[39/50] [200/465] mean_loss : 0.39\n",
      "[39/50] [400/465] mean_loss : 0.40\n",
      "[40/50] [000/465] mean_loss : 0.35\n",
      "[40/50] [200/465] mean_loss : 0.38\n",
      "[40/50] [400/465] mean_loss : 0.38\n",
      "[41/50] [000/465] mean_loss : 0.36\n",
      "[41/50] [200/465] mean_loss : 0.38\n",
      "[41/50] [400/465] mean_loss : 0.38\n",
      "[42/50] [000/465] mean_loss : 0.33\n",
      "[42/50] [200/465] mean_loss : 0.37\n",
      "[42/50] [400/465] mean_loss : 0.37\n",
      "[43/50] [000/465] mean_loss : 0.34\n",
      "[43/50] [200/465] mean_loss : 0.36\n",
      "[43/50] [400/465] mean_loss : 0.37\n",
      "[44/50] [000/465] mean_loss : 0.48\n",
      "[44/50] [200/465] mean_loss : 0.36\n",
      "[44/50] [400/465] mean_loss : 0.36\n",
      "[45/50] [000/465] mean_loss : 0.29\n",
      "[45/50] [200/465] mean_loss : 0.36\n",
      "[45/50] [400/465] mean_loss : 0.35\n",
      "[46/50] [000/465] mean_loss : 0.30\n",
      "[46/50] [200/465] mean_loss : 0.35\n",
      "[46/50] [400/465] mean_loss : 0.36\n",
      "[47/50] [000/465] mean_loss : 0.32\n",
      "[47/50] [200/465] mean_loss : 0.34\n",
      "[47/50] [400/465] mean_loss : 0.35\n",
      "[48/50] [000/465] mean_loss : 0.31\n",
      "[48/50] [200/465] mean_loss : 0.34\n",
      "[48/50] [400/465] mean_loss : 0.34\n",
      "[49/50] [000/465] mean_loss : 0.36\n",
      "[49/50] [200/465] mean_loss : 0.33\n",
      "[49/50] [400/465] mean_loss : 0.35\n"
     ]
    }
   ],
   "source": [
    "loss_to_plot=[]\n",
    "for epoch in range(EPOCH):\n",
    "    losses=[]\n",
    "    for i, batch in enumerate(getBatch(BATCH_SIZE, train_data)):\n",
    "        inputs, targets, input_lengths, target_lengths = pad_to_batch(batch, source_to_index, target_to_index)\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        output, hidden_c = encoder(inputs, input_lengths)\n",
    "        start_decode = Variable(LongTensor([[target_to_index['<s>']] * targets.size(0)])).transpose(0, 1)\n",
    "        input_masks = torch.cat([Variable(ByteTensor(tuple(map(lambda s: s ==0, t.data)))) for t in inputs]).view(inputs.size(0), -1)\n",
    "        preds = decoder(start_decode, hidden_c, targets.size(1), output, input_masks, True)\n",
    "        loss = loss_function(preds, targets.view(-1))\n",
    "        loss_to_plot.append(loss.data.tolist()[0])\n",
    "        losses.append(loss.data.tolist()[0])\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(encoder.parameters(), 50.0) # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm(decoder.parameters(), 50.0) # gradient clipping\n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "\n",
    "        if i % 200==0:\n",
    "            print(\"[%02d/%d] [%03d/%d] mean_loss : %0.2f\" %(epoch, EPOCH, i, len(train_data)//BATCH_SIZE, np.mean(losses)))\n",
    "            losses=[]\n",
    "        if RESCHEDULED == False and epoch  == EPOCH//2:\n",
    "            LR *= 0.01\n",
    "            enc_optimizer = optim.Adam(encoder.parameters(), lr=LR)\n",
    "            dec_optimizer = optim.Adam(decoder.parameters(), lr=LR * DECODER_LEARNING_RATIO)\n",
    "            RESCHEDULED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Skp9aWHy-bJh",
    "outputId": "116aac1d-9eac-4457-a901-ada7698e9e3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23300"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "j2fM3Dda-xrq",
    "outputId": "c4ce8d05-d75e-4fae-b911-256435d57c91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f48a81a3518>]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD4CAYAAAAuNhccAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48ab644198>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(0,23300), loss_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "w6G36-w04gO6",
    "outputId": "1ce9fc4b-6a94-4834-9d2b-be5ac3aaab88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(encoder, 'encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FtIEcrBH40OC",
    "outputId": "a888265a-4d54-4cbd-aea9-4a33021f568f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(decoder, 'decoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "_3nSXkCmynYY",
    "outputId": "88babb3f-4ece-45b4-8000-05aebce1e158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 1000 BLEU: 0.8089463589460244\n",
      "Sentence: 2000 BLEU: 0.8087553566816846\n",
      "Sentence: 3000 BLEU: 0.8106813944707802\n",
      "Sentence: 4000 BLEU: 0.8110109063248789\n",
      "Sentence: 5000 BLEU: 0.8091498486388499\n",
      "Sentence: 6000 BLEU: 0.8092036625592701\n",
      "Sentence: 7000 BLEU: 0.8099321936884741\n",
      "Sentence: 8000 BLEU: 0.8093722941136698\n",
      "Sentence: 9000 BLEU: 0.8093101081693549\n",
      "Sentence: 10000 BLEU: 0.8098745539685914\n",
      "Sentence: 11000 BLEU: 0.8104428974074434\n",
      "Sentence: 12000 BLEU: 0.8099555263038047\n",
      "Sentence: 13000 BLEU: 0.8096860129858382\n",
      "Sentence: 14000 BLEU: 0.8094082113401794\n",
      "Sentence: 15000 BLEU: 0.809225389670784\n",
      "Sentence: 16000 BLEU: 0.8098027522360507\n",
      "Sentence: 17000 BLEU: 0.8087779631886087\n",
      "Sentence: 18000 BLEU: 0.8085321515945479\n",
      "Sentence: 19000 BLEU: 0.8084839850603237\n",
      "Sentence: 20000 BLEU: 0.807972266704642\n",
      "Sentence: 21000 BLEU: 0.8077192318850434\n",
      "Sentence: 22000 BLEU: 0.8077447692221367\n",
      "Sentence: 23000 BLEU: 0.807993059190245\n",
      "Sentence: 24000 BLEU: 0.8081712257161627\n",
      "Sentence: 25000 BLEU: 0.8082771556302055\n",
      "Sentence: 26000 BLEU: 0.8083596965558332\n",
      "Sentence: 27000 BLEU: 0.8082313500821848\n",
      "Sentence: 28000 BLEU: 0.8081079666491032\n",
      "Sentence: 29000 BLEU: 0.8080636018687595\n",
      "Corpus BLEU score: 0.8081983323495406\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BLEU=0\n",
    "for i in range(1, len(train_data)+1):\n",
    "    test = train_data[i-1]\n",
    "    input_ = test[0]\n",
    "    truth = test[1]\n",
    "\n",
    "    output, hidden = encoder(input_, [input_.size(1)])\n",
    "    pred, attn = decoder.decode(hidden, output)\n",
    "\n",
    "    # input_ = [index_to_source[i] for i in input_.data.tolist()[0]]\n",
    "    # pred = [index_to_target[i] for i in pred.data.tolist() if i not in [2, 3]]\n",
    "    # truth = [index_to_target[i] for i in truth.data.tolist()[0] if i not in [2, 3]]\n",
    "\n",
    "    score = sentence_bleu(truth.data.tolist(), pred.data.tolist())\n",
    "    BLEU+=score\n",
    "    if(i%1000==0):\n",
    "        print('Sentence: ' + str(i)+ ' BLEU: ' + str(BLEU/i) )\n",
    "print('Corpus BLEU score: ' + str(BLEU/len(train_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jEwKY_mJsByW"
   },
   "outputs": [],
   "source": [
    "def show_attention(input_words, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_words, rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "#     show_plot_visdom()\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "P1ggzZnvIhQQ",
    "outputId": "ae49bd8a-bb96-4813-a878-f948dd44292c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source :  i m not late , am i ?\n",
      "Truth :  je ne suis pas en retard , n est ce pas ?\n",
      "Prediction :  je ne suis en en pas , est ce pas ?\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAEICAYAAAB735ncAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48a54b7208>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = random.choice(train_data)\n",
    "input_ = test[0]\n",
    "truth = test[1]\n",
    "\n",
    "output, hidden = encoder(input_, [input_.size(1)])\n",
    "pred, attn = decoder.decode(hidden, output)\n",
    "\n",
    "input_ = [index_to_source[i] for i in input_.data.tolist()[0]]\n",
    "pred = [index_to_target[i] for i in pred.data.tolist()]\n",
    "\n",
    "\n",
    "print('Source : ',' '.join([i for i in input_ if i not in ['</s>']]))\n",
    "print('Truth : ',' '.join([index_to_target[i] for i in truth.data.tolist()[0] if i not in [2, 3]]))\n",
    "print('Prediction : ',' '.join([i for i in pred if i not in ['</s>']]))\n",
    "\n",
    "if USE_CUDA:\n",
    "    attn = attn.cpu()\n",
    "\n",
    "show_attention(input_, pred, attn.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z50udkycKwvN",
    "outputId": "e4871d04-3ee6-4991-9015-dfe5f92af68b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['il', 'n', 'y', 'a', 'aucun', 'message', '.']"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQYyemW1LpQH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NMT.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
